{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a719cf94-9b91-4098-b47b-b49056063196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3934c17c-e2b7-4b37-a1b3-85ff3c601088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What exactly is being learned in each chunk? We only take a subset of the edges? \n",
    "#is there a way to ensure that same src edges are being used such that the training learns them together for a given target node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd09946-cf1d-4ecb-b029-eace8cbc950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedMemoryEfficientGATLayer(nn.Module):\n",
    "    def __init__(self, in_features, edge_features, out_features, num_heads, dropout=0.6, leaky_relu_slope=0.2):\n",
    "        super(BatchedMemoryEfficientGATLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.edge_features = edge_features\n",
    "        self.out_features = out_features\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Initial linear layer on node attributes\n",
    "        # self.initial_linear = nn.Linear(in_features, in_features)\n",
    "        \n",
    "        # Increased projection size (2x out_features)\n",
    "        self.W = nn.Linear(in_features, num_heads * 1 * out_features, bias=False)\n",
    "        \n",
    "        # Adjust attention parameter size for increased projection\n",
    "        self.a = nn.Parameter(torch.empty(size=(num_heads, 2 * (1 * out_features) + edge_features)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "        # Final projection to out_features\n",
    "        self.final_projection = nn.Linear(1 * out_features, out_features)\n",
    "        \n",
    "        self.leaky_relu = nn.LeakyReLU(leaky_relu_slope)\n",
    "\n",
    "    def _neighborhood_aware_softmax(self, attention_scores, edge_index_chunk, num_nodes):\n",
    "        batch_size, chunk_size, num_heads = attention_scores.size()\n",
    "        \n",
    "        # Initialize the output tensor\n",
    "        normalized_scores = torch.zeros_like(attention_scores)\n",
    "        \n",
    "        # Process each batch separately\n",
    "        for b in range(batch_size):\n",
    "            # Create tensors for source and destination nodes\n",
    "            src_nodes = edge_index_chunk[b, 0]\n",
    "            dst_nodes = edge_index_chunk[b, 1]\n",
    "            \n",
    "            # Compute max for numerical stability\n",
    "            max_scores = torch.zeros(num_nodes, num_heads, device=attention_scores.device)\n",
    "            max_scores.index_reduce_(0, dst_nodes, attention_scores[b], 'amax')\n",
    "            \n",
    "            # Compute exponentials\n",
    "            exp_scores = torch.exp(attention_scores[b] - max_scores[dst_nodes])\n",
    "            \n",
    "            # Compute sum of exponentials for each destination node\n",
    "            sum_exp = torch.zeros(num_nodes, num_heads, device=attention_scores.device)\n",
    "            sum_exp.index_add_(0, dst_nodes, exp_scores)\n",
    "            \n",
    "            # Compute normalized scores\n",
    "            normalized_scores[b] = exp_scores / sum_exp[dst_nodes].clamp(min=1e-12)\n",
    "        \n",
    "        return normalized_scores\n",
    "\n",
    "    # def _neighborhood_aware_softmax(self, attention_scores, edge_index_chunk, num_nodes):\n",
    "    #     batch_size, chunk_size, num_heads = attention_scores.size()\n",
    "        \n",
    "    #     # Compute max for numerical stability\n",
    "    #     max_scores = torch.zeros(batch_size, num_nodes, num_heads, device=attention_scores.device)\n",
    "    #     max_scores.scatter_reduce_(1, edge_index_chunk[:, 1].unsqueeze(-1).expand(-1, -1, num_heads), \n",
    "    #                                attention_scores, reduce='amax')\n",
    "        \n",
    "    #     # Compute exponentials\n",
    "    #     exp_scores = torch.exp(attention_scores - max_scores.gather(1, edge_index_chunk[:, 1].unsqueeze(-1).expand(-1, -1, num_heads)))\n",
    "        \n",
    "    #     # Compute sum of exponentials for each destination node\n",
    "    #     sum_exp = torch.zeros(batch_size, num_nodes, num_heads, device=attention_scores.device)\n",
    "    #     sum_exp.scatter_add_(1, edge_index_chunk[:, 1].unsqueeze(-1).expand(-1, -1, num_heads), exp_scores)\n",
    "        \n",
    "    #     # Compute normalized scores\n",
    "    #     normalized_scores = exp_scores / (sum_exp.gather(1, edge_index_chunk[:, 1].unsqueeze(-1).expand(-1, -1, num_heads)) + 1e-12)\n",
    "        \n",
    "    #     return normalized_scores\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, edge_distance):\n",
    "        batch_size, N, _ = x.size()\n",
    "        \n",
    "        # Apply initial linear layer\n",
    "        # x = self.initial_linear(x)\n",
    "        \n",
    "        # Increased projection\n",
    "        h = self.W(x).view(batch_size, N, self.num_heads, -1)  # [batch_size, N, num_heads, 2*out_features]\n",
    "        \n",
    "        # Combine edge_attr and edge_distance\n",
    "        edge_features = torch.cat([edge_attr.unsqueeze(-1), edge_distance.unsqueeze(-1)], dim=-1)\n",
    "        \n",
    "        # Process edges in chunks to save memory\n",
    "        chunk_size = 8 * 1_000  # Adjust this based on available memory\n",
    "        num_edges = edge_index.size(2)\n",
    "        h_prime = torch.zeros_like(h)\n",
    "        \n",
    "        for i in range(0, num_edges, chunk_size):\n",
    "            edge_index_chunk = edge_index[:, :, i:i+chunk_size]\n",
    "            edge_features_chunk = edge_features[:, i:i+chunk_size, :].unsqueeze(1).permute([0, 2, 1, 3])\n",
    "            \n",
    "            h_src = h.gather(1, edge_index_chunk[:, 0, :].unsqueeze(-1).unsqueeze(-1).expand(-1, -1, self.num_heads, h.size(-1)))\n",
    "            h_dst = h.gather(1, edge_index_chunk[:, 1, :].unsqueeze(-1).unsqueeze(-1).expand(-1, -1, self.num_heads, h.size(-1)))\n",
    "            \n",
    "            # Compute attention coefficients\n",
    "            # Compute attention coefficients\n",
    "            edge_h = torch.cat([h_src, h_dst, edge_features_chunk], dim=-1)\n",
    "            edge_e = self.leaky_relu((self.a.view(1, 1, self.num_heads, -1) * edge_h).sum(dim=-1))\n",
    "            attention = self._neighborhood_aware_softmax(edge_e, edge_index_chunk, N)\n",
    "            \n",
    "            # Apply dropout to attention weights\n",
    "            attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "            \n",
    "            # Apply attention coefficients\n",
    "            weighted_features = attention.unsqueeze(-1) * h_src\n",
    "            for b in range(batch_size):\n",
    "                h_prime[b].scatter_add_(0, \n",
    "                    edge_index_chunk[b, 1].view(-1, 1, 1).expand(-1, self.num_heads, h.size(-1)), \n",
    "                    weighted_features[b]\n",
    "                )\n",
    "        \n",
    "        # Average over heads and apply final projection\n",
    "        h_prime = h_prime.mean(dim=2)  # [batch_size, N, 2*out_features]\n",
    "        return self.final_projection(h_prime)  # [batch_size, N, out_features]\n",
    "\n",
    "class BatchedMemoryEfficientGAT(nn.Module):\n",
    "    def __init__(self, num_features, edge_features, hidden_size, num_classes, num_heads, num_layers=2):\n",
    "        super(BatchedMemoryEfficientGAT, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        \n",
    "        self.gat_layers.append(BatchedMemoryEfficientGATLayer(num_features, edge_features, hidden_size, num_heads))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.gat_layers.append(BatchedMemoryEfficientGATLayer(hidden_size, edge_features, hidden_size, num_heads))\n",
    "        self.gat_layers.append(BatchedMemoryEfficientGATLayer(hidden_size, edge_features, num_classes, 1))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, edge_distance):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = F.elu(self.gat_layers[i](x, edge_index, edge_attr, edge_distance))\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = self.gat_layers[-1](x, edge_index, edge_attr, edge_distance)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb91081-5e22-4514-8ab5-2a4cbf75091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluid_simulation.utils import create_grid_graph_with_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1dee0c8-77bf-4533-b6a8-199793dbf9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class GridDatasetGNN(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_cols, height, width):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing simulation data with columns ['simulation_id', 'timestep', 'row', 'col', ...].\n",
    "            feature_cols (list): List of column names to be used as input features.\n",
    "            target_cols (list): List of column names to be used as target features.\n",
    "            height (int): Number of rows in the grid.\n",
    "            width (int): Number of columns in the grid.\n",
    "        \"\"\"\n",
    "        super(GridDatasetGNN, self).__init__()\n",
    "        self.df = df\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_cols\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.graph = create_grid_graph_with_angles(height, width)\n",
    "        self.data_list = self.process_data()\n",
    "\n",
    "    def process_data(self):\n",
    "        data_list = []\n",
    "        grouped = self.df.groupby(['simulation_id', 'timestep'])\n",
    "        for (sim_id, timestep), group in grouped:\n",
    "            assert group[['row', 'col']].duplicated().sum() == 0, \"Duplicate (row, col) found.\"\n",
    "            \n",
    "            group = group.sort_values(['row', 'col']).reset_index(drop=True)\n",
    "            \n",
    "            features = group[self.feature_cols].values.astype(np.float32)\n",
    "            x = torch.tensor(features, dtype=torch.float)\n",
    "            y = torch.tensor(group[self.target_cols].values.astype(np.float32), dtype=torch.float)\n",
    "            \n",
    "            data = {\n",
    "                'x': x,\n",
    "                'edge_index': self.graph['edge_index'],\n",
    "                'edge_attr': self.graph['edge_attr'],\n",
    "                'edge_distance': self.graph['edge_distance'],\n",
    "                'y': y\n",
    "            }\n",
    "            data_list.append(data)\n",
    "        return data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d0159c-815d-4403-8624-bf6ae47c24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fluid_simulation.models_v2 import CNN, GridGNNWithAngles\n",
    "from fluid_simulation.utils import prepare_data, calculate_deltas, prepare_data_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321babf6-bb3a-4b50-adc7-48770e7aeab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440000, 19)\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "csv_file = '../../combined_mac_data_with_deltas.csv'\n",
    "\n",
    "timestep_n_rows = 14400\n",
    "n_steps = 100\n",
    "df = pd.read_csv(csv_file, nrows=timestep_n_rows * n_steps)\n",
    "df2 = pd.read_csv(csv_file, nrows=timestep_n_rows * n_steps, skiprows=timestep_n_rows * 100)\n",
    "\n",
    "df2.columns = df.columns\n",
    "print(df.shape)\n",
    "print(df.shape[0] // 51_200)\n",
    "df = pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "699442e6-0a14-4249-8e1a-005e9c70c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = df.select_dtypes(include=['float64', 'float32']).columns\n",
    "df[float_columns] = (df[float_columns] - df[float_columns].mean()) / df[float_columns].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1700a9f9-b2d0-497b-8c3f-9eb60494362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df.row > 60) & (df.row < 80) & (df.density > 0.2)].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235e4108-3eeb-4d44-b676-2300f9e14eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "671d8fb9-5ac0-4afc-97f2-6dc6fd2907c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input columns: ['u', 'v', 'density', 'is_fluid', 'border']\n",
      "Target columns: ['u_next', 'v_next', 'density_next', 'is_fluid_next']\n"
     ]
    }
   ],
   "source": [
    "df, input_cols, target_cols = prepare_data_v2(df, target_pattern=\"_next\", input_pattern_filter_2=\"delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79e4e579-462a-4aba-98d8-cf4c09e91b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>time</th>\n",
       "      <th>timestep</th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>density</th>\n",
       "      <th>pressure</th>\n",
       "      <th>is_fluid</th>\n",
       "      <th>simulation_id</th>\n",
       "      <th>iter_next</th>\n",
       "      <th>time_next</th>\n",
       "      <th>timestep_next</th>\n",
       "      <th>u_next</th>\n",
       "      <th>v_next</th>\n",
       "      <th>density_next</th>\n",
       "      <th>pressure_next</th>\n",
       "      <th>is_fluid_next</th>\n",
       "      <th>border</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>511324</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.502320</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.187416</td>\n",
       "      <td>4.177571</td>\n",
       "      <td>0.201910</td>\n",
       "      <td>0.865086</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.489898</td>\n",
       "      <td>-0.489898</td>\n",
       "      <td>-1.138904</td>\n",
       "      <td>4.185802</td>\n",
       "      <td>0.260399</td>\n",
       "      <td>0.771701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511325</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.502320</td>\n",
       "      <td>35</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.888408</td>\n",
       "      <td>4.820344</td>\n",
       "      <td>0.210081</td>\n",
       "      <td>1.415486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.489898</td>\n",
       "      <td>-0.489898</td>\n",
       "      <td>-0.830273</td>\n",
       "      <td>4.833810</td>\n",
       "      <td>0.283502</td>\n",
       "      <td>1.312208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525724</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.467677</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.141350</td>\n",
       "      <td>4.206091</td>\n",
       "      <td>0.262861</td>\n",
       "      <td>0.777781</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>-1.087848</td>\n",
       "      <td>4.201270</td>\n",
       "      <td>0.324587</td>\n",
       "      <td>0.680808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525725</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.467677</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.831515</td>\n",
       "      <td>4.857214</td>\n",
       "      <td>0.286056</td>\n",
       "      <td>1.319596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>-0.454905</td>\n",
       "      <td>-0.767477</td>\n",
       "      <td>4.852431</td>\n",
       "      <td>0.364575</td>\n",
       "      <td>1.210543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540123</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.433034</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.453723</td>\n",
       "      <td>3.557919</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.250830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-1.404165</td>\n",
       "      <td>3.555749</td>\n",
       "      <td>0.267096</td>\n",
       "      <td>0.171317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540124</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.433034</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.090095</td>\n",
       "      <td>4.221633</td>\n",
       "      <td>0.327305</td>\n",
       "      <td>0.686668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-1.032777</td>\n",
       "      <td>4.204574</td>\n",
       "      <td>0.391496</td>\n",
       "      <td>0.586519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540125</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.433034</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.768474</td>\n",
       "      <td>4.875925</td>\n",
       "      <td>0.367452</td>\n",
       "      <td>1.217685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.700162</td>\n",
       "      <td>4.854117</td>\n",
       "      <td>0.449836</td>\n",
       "      <td>1.103321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540126</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.433034</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.553296</td>\n",
       "      <td>5.460904</td>\n",
       "      <td>0.280671</td>\n",
       "      <td>1.810637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.419912</td>\n",
       "      <td>-0.473742</td>\n",
       "      <td>5.458790</td>\n",
       "      <td>0.378257</td>\n",
       "      <td>1.693235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554523</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.398392</td>\n",
       "      <td>38</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.407646</td>\n",
       "      <td>3.573008</td>\n",
       "      <td>0.269585</td>\n",
       "      <td>0.175943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.384920</td>\n",
       "      <td>-0.384920</td>\n",
       "      <td>-1.354625</td>\n",
       "      <td>3.561823</td>\n",
       "      <td>0.320596</td>\n",
       "      <td>0.094979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554524</th>\n",
       "      <td>750</td>\n",
       "      <td>-0.398392</td>\n",
       "      <td>38</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.034809</td>\n",
       "      <td>4.224953</td>\n",
       "      <td>0.394480</td>\n",
       "      <td>0.592151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.384920</td>\n",
       "      <td>-0.384920</td>\n",
       "      <td>-0.974810</td>\n",
       "      <td>4.196581</td>\n",
       "      <td>0.460309</td>\n",
       "      <td>0.489364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        iter      time  timestep  row  col         u         v   density  \\\n",
       "511324   750 -0.502320        35   61    4 -1.187416  4.177571  0.201910   \n",
       "511325   750 -0.502320        35   61    5 -0.888408  4.820344  0.210081   \n",
       "525724   750 -0.467677        36   61    4 -1.141350  4.206091  0.262861   \n",
       "525725   750 -0.467677        36   61    5 -0.831515  4.857214  0.286056   \n",
       "540123   750 -0.433034        37   61    3 -1.453723  3.557919  0.217778   \n",
       "540124   750 -0.433034        37   61    4 -1.090095  4.221633  0.327305   \n",
       "540125   750 -0.433034        37   61    5 -0.768474  4.875925  0.367452   \n",
       "540126   750 -0.433034        37   61    6 -0.553296  5.460904  0.280671   \n",
       "554523   750 -0.398392        38   61    3 -1.407646  3.573008  0.269585   \n",
       "554524   750 -0.398392        38   61    4 -1.034809  4.224953  0.394480   \n",
       "\n",
       "        pressure  is_fluid  simulation_id  iter_next  time_next  \\\n",
       "511324  0.865086         1              0        NaN  -0.489898   \n",
       "511325  1.415486         1              0        NaN  -0.489898   \n",
       "525724  0.777781         1              0        NaN  -0.454905   \n",
       "525725  1.319596         1              0        NaN  -0.454905   \n",
       "540123  0.250830         1              0        NaN  -0.419912   \n",
       "540124  0.686668         1              0        NaN  -0.419912   \n",
       "540125  1.217685         1              0        NaN  -0.419912   \n",
       "540126  1.810637         1              0        NaN  -0.419912   \n",
       "554523  0.175943         1              0        NaN  -0.384920   \n",
       "554524  0.592151         1              0        NaN  -0.384920   \n",
       "\n",
       "        timestep_next    u_next    v_next  density_next  pressure_next  \\\n",
       "511324      -0.489898 -1.138904  4.185802      0.260399       0.771701   \n",
       "511325      -0.489898 -0.830273  4.833810      0.283502       1.312208   \n",
       "525724      -0.454905 -1.087848  4.201270      0.324587       0.680808   \n",
       "525725      -0.454905 -0.767477  4.852431      0.364575       1.210543   \n",
       "540123      -0.419912 -1.404165  3.555749      0.267096       0.171317   \n",
       "540124      -0.419912 -1.032777  4.204574      0.391496       0.586519   \n",
       "540125      -0.419912 -0.700162  4.854117      0.449836       1.103321   \n",
       "540126      -0.419912 -0.473742  5.458790      0.378257       1.693235   \n",
       "554523      -0.384920 -1.354625  3.561823      0.320596       0.094979   \n",
       "554524      -0.384920 -0.974810  4.196581      0.460309       0.489364   \n",
       "\n",
       "        is_fluid_next  border  \n",
       "511324            NaN     0.0  \n",
       "511325            NaN     0.0  \n",
       "525724            NaN     0.0  \n",
       "525725            NaN     0.0  \n",
       "540123            NaN     0.0  \n",
       "540124            NaN     0.0  \n",
       "540125            NaN     0.0  \n",
       "540126            NaN     0.0  \n",
       "554523            NaN     0.0  \n",
       "554524            NaN     0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.row > 60) & (df.row < 80) & (df.density > 0.2)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453c3e41-667b-45e9-94fd-84912089bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_gnn = GridDatasetGNN(\n",
    "    df=df, feature_cols=input_cols, target_cols=target_cols, height=160,width=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bfffaa5-b0c3-44b5-825b-e854ba227f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffea5e1e-5736-48f7-9ce4-e5ada59e3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "\n",
    "model_gnn = BatchedMemoryEfficientGAT(\n",
    "    num_features=len(input_cols),\n",
    "    num_classes=len(target_cols),\n",
    "    edge_features=2,\n",
    "    hidden_size=16,\n",
    "    num_heads=1,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "332eead8-18ca-4a7e-a70b-e98006573361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'edge_index', 'edge_attr', 'edge_distance', 'y'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/6kqmsx2j5cqbycjcbrjng36h0000gn/T/ipykernel_37329/1371692449.py:39: UserWarning: The operator 'aten::index_reduce.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  max_scores.index_reduce_(0, dst_nodes, attention_scores[b], 'amax')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m edge_distance \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_distance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Compute loss, backpropagate, etc.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 133\u001b[0m, in \u001b[0;36mBatchedMemoryEfficientGAT.forward\u001b[0;34m(self, x, edge_index, edge_attr, edge_distance)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr, edge_distance):\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 133\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgat_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_distance\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    134\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    136\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](x, edge_index, edge_attr, edge_distance)\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 101\u001b[0m, in \u001b[0;36mBatchedMemoryEfficientGATLayer.forward\u001b[0;34m(self, x, edge_index, edge_attr, edge_distance)\u001b[0m\n\u001b[1;32m     99\u001b[0m edge_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h_src, h_dst, edge_features_chunk], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    100\u001b[0m edge_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m edge_h)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 101\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neighborhood_aware_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Apply dropout to attention weights\u001b[39;00m\n\u001b[1;32m    104\u001b[0m attention \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(attention, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mBatchedMemoryEfficientGATLayer._neighborhood_aware_softmax\u001b[0;34m(self, attention_scores, edge_index_chunk, num_nodes)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute max for numerical stability\u001b[39;00m\n\u001b[1;32m     38\u001b[0m max_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(num_nodes, num_heads, device\u001b[38;5;241m=\u001b[39mattention_scores\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmax_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_reduce_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Compute exponentials\u001b[39;00m\n\u001b[1;32m     42\u001b[0m exp_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(attention_scores[b] \u001b[38;5;241m-\u001b[39m max_scores[dst_nodes])\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "loader_gnn = DataLoader(dataset_gnn, batch_size=batch_size, shuffle=True)\n",
    "# Example: Iterate through the DataLoader\n",
    "for batch in loader_gnn:\n",
    "    # batch.x: [batch_size * num_nodes, in_features]\n",
    "    # batch.edge_index: [2, batch_size * 4 * num_nodes]\n",
    "    # batch.y: [batch_size * num_nodes, target_features]\n",
    "    print(batch.keys())\n",
    "    x = batch['x'].to(device)\n",
    "    edge_index = batch['edge_index'].to(device)\n",
    "    edge_attr = batch['edge_attr'].to(device)\n",
    "    edge_distance = batch['edge_distance'].to(device)\n",
    "    output = model_gnn(x, edge_index, edge_attr, edge_distance)\n",
    "    print(edge_attr.shape)\n",
    "    # Compute loss, backpropagate, etc.\n",
    "    print(output.shape)\n",
    "    break  # Remove this to iterate through the entire dataset\n",
    "print('---- GNN is Valid ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ebb427d-19ea-4cc7-876e-b04904eb12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn\n",
    "import os\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=10, learning_rate=0.001, device=None, model_type=\"gnn\"):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Add LR scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=4, gamma=0.92)  # Reduce LR by factor of 0.1 every 5 epochs\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f'Starting training: {next(model.parameters()).device}')\n",
    "    print('params')\n",
    "    print(sum(p.numel() for p in model_gnn.parameters() if p.requires_grad))\n",
    "    print(sum(p.numel() for p in model.gat_layers[0].parameters() if p.requires_grad))\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        i = 0\n",
    "        for batch in dataloader:\n",
    "            x = batch['x'].to(device)\n",
    "            edge_index = batch['edge_index'].to(device)\n",
    "            edge_attr = batch['edge_attr'].to(device)\n",
    "            edge_distance = batch['edge_distance'].to(device)\n",
    "            output = model_gnn(x, edge_index, edge_attr, edge_distance)\n",
    "            # Assume targets are binary (0 or 1)\n",
    "            loss = criterion(batch['y'].to(device), output)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        # if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    print('Finished training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e7eb7cf-8106-4183-b6d5-f9604d620c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72258241-71cf-4b0a-88e3-e1d414571a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training: mps:0\n",
      "params\n",
      "480\n",
      "386\n",
      "Epoch 1/25, Loss: 491.7283, LR: 0.001000\n",
      "Epoch 2/25, Loss: 453.2777, LR: 0.001000\n",
      "Epoch 3/25, Loss: 458.7526, LR: 0.001000\n",
      "Epoch 4/25, Loss: 460.1987, LR: 0.000920\n",
      "Epoch 5/25, Loss: 466.4615, LR: 0.000920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gnn_trained \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_gnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader_gnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, num_epochs, learning_rate, device, model_type)\u001b[0m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), output)\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     38\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/fluid-simulation/fluid-simulation/fluid-simulation/py/venv/lib/python3.9/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gnn_trained = train_model(\n",
    "    model_gnn, \n",
    "    loader_gnn, \n",
    "    num_epochs=n_epochs, \n",
    "    learning_rate=0.001, \n",
    "    device=device, \n",
    "    model_type=\"gnn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abfa9f-e9fb-4823-96e2-0c00f967c143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
